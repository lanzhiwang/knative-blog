# SERIES: DEPLOYING AND AUTOSCALING KUBERNETES WITH KNATIVE

* https://www.nearform.com/blog/deploying-autoscaling-kubernetes-knative/

## Series: Kubernetes Services Deployment, Autoscaling and Monitoring, Part 1
系列：Kubernetes 服务部署、自动扩展和监控，第 1 部分

At NearForm we are always learning and investigating new ways to work with the open source projects we use in our client projects. The nature of Open Source projects means that they are always being upgraded and improved upon with new features and platforms popping up on a consistent basis. For this reason it is crucial for our developers to stay abreast of the latest trends, technologies and best practices.
在 NearForm，我们一直在学习和研究使用我们在客户项目中使用的开源项目的新方法。 开源项目的性质意味着它们总是在不断升级和改进，新功能和平台不断涌现。 因此，我们的开发人员了解最新趋势、技术和最佳实践至关重要。

Our DevOps community recently did some research on kubernetes services deployment, autoscaling and monitoring and we are sharing the results of their investigation here.
我们的 DevOps 社区最近对 kubernetes 服务部署、自动扩展和监控进行了一些研究，我们在这里分享他们的调查结果。

1. Deploying and Autoscaling Kubernetes with Knative
   使用 Knative 部署和自动扩展 Kubernetes

2. [Autoscaling Kubernetes Services with Keda](https://www.nearform.com/blog/autoscaling-kubernetes-with-keda/)
   使用 Keda 自动扩展 Kubernetes 服务

3. Monitoring and Tracing Kubernetes Services with Otel
   使用 Otel 监控和跟踪 Kubernetes 服务

### Kubernetes Overview

Kubernetes (K8s) is an open source platform for automating deployment, scaling, and management of containerized applications. It groups containers that make up an application into logical units for easy management and discovery. Kubernetes builds upon 15 years of experience running production workloads at Google, combined with best-of-breed ideas and practices from the community.
Kubernetes (K8s) 是一个开源平台，用于自动化容器化应用程序的部署、扩展和管理。 它将组成应用程序的容器分组为逻辑单元，以便于管理和发现。 Kubernetes 建立在 Google 15 年运行生产工作负载的经验之上，并结合了社区的最佳想法和实践。

Kubernetes provides a powerful API that enables third-party tools to provision, secure, connect and manage workloads on any cloud or infrastructure platform. It also includes features that help you automate control plane operations such as rollout cadence, versioning and rollback.
Kubernetes 提供了强大的 API，使第三方工具能够在任何云或基础设施平台上配置、保护、连接和管理工作负载。 它还包括帮助您自动化控制平面操作的功能，例如推出节奏、版本控制和回滚。

Kubernetes is ideal for organizations that want to run containerized applications at scale.
Kubernetes 非常适合想要大规模运行容器化应用程序的组织。

Many organizations now run entire business functions in containers instead of traditional applications. This shift requires changes in how IT operates – from managing virtual machines to managing container orchestrators like Kubernetes. Business leaders are demanding more agility from their IT departments to support fast-moving projects with new technologies like [microservices architecture](https://www.nearform.com/services/enterprise-backend-development/), [serverless computing](https://www.nearform.com/services/enterprise-serverless-architecture/) and [cloud native computing platforms](https://www.nearform.com/services/enterprise-cloud-native-infrastructure/) like OpenShift Container Platform or Azure Kubernetes Service (AKS).
许多组织现在在容器而不是传统应用程序中运行整个业务功能。 这种转变需要 IT 运营方式的改变——从管理虚拟机到管理 Kubernetes 等容器编排器。 企业领导者要求 IT 部门提高敏捷性，利用微服务架构、无服务器计算和 OpenShift 容器平台或 Azure Kubernetes Service (AKS) 等云原生计算平台等新技术来支持快速发展的项目。

### What is Knative?

Knative is a platform that enables serverless cloud native applications to run inside Kubernetes clusters. In order to do that, Knative has tools to make the application management, build and deployment as easy as possible, so developers can focus on the code without needing to worry about setting up complex infrastructure.
Knative 是一个使无服务器云原生应用程序能够在 Kubernetes 集群内运行的平台。 为了做到这一点，Knative 拥有使应用程序管理、构建和部署尽可能简单的工具，因此开发人员可以专注于代码，而无需担心设置复杂的基础设施。

It was originally created by Google with contributions from several different companies until it became an open source project hosted by the [Cloud Native Computing Foundation (CNCF)](https://www.cncf.io/projects/knative/).
它最初由 Google 创建，并得到了多家不同公司的贡献，直到成为云原生计算基金会 (CNCF) 托管的开源项目。

### Exploring Knative
探索 Knative

Knative offers two main solutions for [serverless Kubernetes-based applications](https://www.nearform.com/services/secure-kubernetes-architecture/):
Knative 为基于 Kubernetes 的无服务器应用程序提供了两种主要解决方案：

- **Knative Serving**:
  enables serverless workloads for applications inside Kubernetes
  为 Kubernetes 内的应用程序启用无服务器工作负载

- **Knative Eventing**:
  enables you to use an event-driven architecture with your serverless application
  使您能够在无服务器应用程序中使用事件驱动架构

This article will focus only on the [Knative Serving](https://knative.dev/docs/serving/) solution.
本文将仅关注 Knative Serving 解决方案。

#### Installation

First of all, follow the steps described [here](https://knative.dev/docs/install/), in order to install Knative on your cluster. Choose the installation option that will best suit your needs. Be aware that, if you are installing in a pre-existing Kubernetes cluster, Knative needs to use a service mesh in order to properly function. So, if you don’t have one configured, you will need to install one (the documentation has a few examples of [service meshes](https://knative.dev/docs/install/yaml-install/serving/install-serving-with-yaml/#install-a-networking-layer) that you can use).
首先，按照此处描述的步骤操作，以便在集群上安装 Knative。 选择最适合您需求的安装选项。 请注意，如果您要安装在预先存在的 Kubernetes 集群中，Knative 需要使用服务网格才能正常运行。 因此，如果您没有配置，则需要安装一个（文档中有一些您可以使用的服务网格示例）。

#### Knative

Knative Serving is the solution used to enable serverless workloads. In order for the solution to be able to define and control how serverless workloads behave and manage the underlying Kubernetes objects, Knative defines a set of Kubernetes Custom Resource Definitions (CRDs).
Knative Serving 是用于支持无服务器工作负载的解决方案。 为了使解决方案能够定义和控制无服务器工作负载的行为方式并管理底层 Kubernetes 对象，Knative 定义了一组 Kubernetes 自定义资源定义 (CRD)。

##### The Custom Resource Definitions are:

- **Services**:
  Manages the entire lifecycle of your workload and is the main resource, since it also controls the creation of the other resources and ensures that they are working properly
  管理工作负载的整个生命周期，并且是主要资源，因为它还控制其他资源的创建并确保它们正常工作

- **Routes**:
  Maps a network endpoint to one or more revisions
  将网络端点映射到一个或多个修订版本

- **Configurations**:
  Resource used to maintain the desired state of your deployment by creating new a new revision when the configuration changes
  用于在配置更改时通过创建新修订版来维护部署的所需状态的资源

- **Revisions**:
  Point-in-time snapshot of the code and the configuration
  代码和配置的时间点快照

You can find more detailed information regarding the CRDs managed by Knative on its documentation: [Overview - Knative](https://knative.dev/docs/serving/)
您可以在其文档中找到有关 Knative 管理的 CRD 的更多详细信息：https://knative.dev/docs/serving/

### Benefits of Knative
Knative 的好处

Knative comes with a collection of solutions that aims to give you a more robust way to manage your cloud native applications out of the box. It also reduces the amount of complexity in terms of how to do it. Below we listed a few benefits of using Knative in your infrastructure
Knative 附带了一系列解决方案，旨在为您提供一种更强大的方式来管理开箱即用的云原生应用程序。 它还降低了如何做到这一点的复杂性。 下面我们列出了在基础设施中使用 Knative 的一些好处

#### Autoscaling
自动缩放

Knative provides autoscaling to the K8s pods managed by the Knative Services (CRD).
Knative 为 Knative Services (CRD) 管理的 K8s Pod 提供自动缩放功能。

Knative implements an autoscaling solution called Knative Pod Autoscaler (KPA) that you can use with your applications, providing the features below:
Knative 实现了一个名为 Knative Pod Autoscaler (KPA) 的自动缩放解决方案，您可以将其与您的应用程序一起使用，并提供以下功能：

- **Scale-To-Zero**:
  Knative uses the Knative Pod Autoscaler (KPA) by default. With KPA you can scale your application to zero pods, if the application is not receiving any traffic.
  Knative 默认使用 Knative Pod Autoscaler (KPA)。 使用 KPA，如果应用程序未接收任何流量，您可以将应用程序扩展到零 pod。

- **Concurrency**:
  You can use the Concurrency configuration, to determine how many simultaneous connections your pods can process at any given time. If the number of requests exceeds the threshold for each pod, Knative will scale up the number of pods.
  您可以使用并发配置来确定 pod 在任何给定时间可以处理的并发连接数。 如果请求数量超过每个 Pod 的阈值，Knative 将扩展 Pod 数量。

- **Requests Per Second**:
  You can also use Knative to define how many requests per second each pod can handle. If the number of requests per second exceeds the threshold, Knative will scale up the number of pods.
  您还可以使用 Knative 定义每个 pod 每秒可以处理的请求数。 如果每秒的请求数超过阈值，Knative 将扩展 pod 数量。

You can also use Horizontal Pod Autoscaler (HPA) with Knative but, HPA and KPA can’t be used for the same service together. (HPA is not installed by Knative, if you want to use it, you need to install it separately). KPA is used by default, but you can control which type of autoscaler to use, through annotations in the service definitions.
您还可以将 Horizontal Pod Autoscaler (HPA) 与 Knative 结合使用，但是 HPA 和 KPA 不能一起用于同一服务。 （HPA不是Knative安装的，如果要使用需要单独安装）。 默认情况下使用 KPA，但您可以通过服务定义中的注释来控制要使用哪种类型的自动缩放器。

For HPA:

```yaml
apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: sample-knative-svc
spec:
  template:
    metadata:
      annotations:
        autoscaling.knative.dev/class: "hpa.autoscaling.knative.dev"
```

For KPA:

```yaml
apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: sample-knative-svc
spec:
  template:
    metadata:
      annotations:
        autoscaling.knative.dev/class: "kpa.autoscaling.knative.dev"
```

Using a similar approach, you can define the type of metric you want to use to autoscale your service and also determine the target to be reached in order to trigger it.
使用类似的方法，您可以定义要用于自动扩展服务的指标类型，还可以确定要达到的目标以触发它。

```yaml
apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: sample-knative-svc
spec:
  template:
    metadata:
      annotations:
        autoscaling.knative.dev/class: "kpa.autoscaling.knative.dev"
        autoscaling.knative.dev/metric: "concurrency"
        autoscaling.knative.dev/target: "50"
```

Take a look at here [to learn more about autoscaling in Knative](https://knative.dev/docs/serving/autoscaling/)

#### Traffic Management

With this feature, you can manage routing traffic to different revisions of your configuration, by only making a few changes in a yaml file. Thanks to this, you can use a few features that would be hard to manage if you were only using Kubernetes plain objects, like:
借助此功能，您只需在 yaml 文件中进行一些更改即可管理路由流量到配置的不同版本。 因此，您可以使用一些如果仅使用 Kubernetes 普通对象则难以管理的功能，例如：

##### Blue/Green Deployments:
蓝/绿部署：

```yaml
apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: example-service
  namespace: default
spec:
...
  traffic:
  - percent: 0
    revisionName: example-service-v1
    tag: staging
  - percent: 40
    revisionName: example-service-v2
  - percent: 60
    revisionName: example-service-v3
```

You can use the following kn CLI command to split traffic between revisions:
您可以使用以下 kn CLI 命令在修订版本之间拆分流量：

```bash
kn service update <service-name> --traffic <revision-name>=<percent>
```

- <service-name> is the name of the Knative Service that you are configuring traffic routing for.
- <revision-name> is the name of the revision that you want to configure to receive a percentage of traffic.
- <percent> is the percentage of traffic that you want to send to the revision specified by <revision-name>.

Example:

```bash
kn service update example-service –traffic example-service-v1=75 –traffic example-service-v2=25
```

Alternatively, you can use the traffic section to perform canary deployments with yaml configuration files like the example:
或者，您可以使用流量部分通过 yaml 配置文件执行金丝雀部署，如下例所示：

```yaml
apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: example-service
  namespace: default
spec:
...
  traffic:
  - tag: current
    revisionName: example-service-v1
    percent: 75
  - tag: candidate
    revisionName: example-service-v2
    percent: 25
```

You can gradually update the percent values by applying the yaml file changes with the `kubectl apply` command.
您可以通过使用“kubectl apply”命令应用 yaml 文件更改来逐渐更新百分比值。

With this approach you can rotate the revision versions using Canary and Blue/Green deployments.
通过这种方法，您可以使用金丝雀和蓝/绿部署轮换修订版本。

You can also achieve the same behavior by managing another Knative resource: routes.
您还可以通过管理另一个 Knative 资源：路由来实现相同的行为。

This approach will avoid changing the Knative Service yaml file.
这种方法将避免更改 Knative Service yaml 文件。

Route example:

```yaml
apiVersion: serving.knative.dev/v1
kind: Route
metadata:
  name: example-service-route
  namespace: default
spec:
  traffic:
  - revisionName: example-service-v1
    percent: 100 # All traffic goes to this revision
```

- <route-name> is the name you choose for your route.
- <first-revision-name> is the name of the initial Revision from the previous step.

Example:

```yaml
apiVersion: serving.knative.dev/v1
kind: Route
metadata:
  name: example-service-route
  namespace: default
spec:
  traffic:
    - tag: blue
      revisionName: example-service-v1
      percent: 75
    - tag: green
      revisionName: example-service-v2
      percent: 25
```

Once the candidate revision is validated, you can rotate all the traffic to it and perform a Blue/Green deployment:

```yaml
apiVersion: serving.knative.dev/v1
kind: Route
metadata:
  name: example-service-route
  namespace: default
spec:
  traffic:
    - tag: blue
      revisionName: example-service-v1
      percent: 0
    - tag: green
      revisionName: example-service-v2
      percent: 100
```

#### Simpler Configuration
配置更简单

Last but not the least, Knative enables you to provision a slightly complex setup for your application using only a few lines of code.
最后但并非最不重要的一点是，Knative 使您能够仅使用几行代码为您的应用程序提供稍微复杂的设置。

In this first example we define all the needed components to deploy a simple demonstration app in Kubernetes.
在第一个示例中，我们定义了在 Kubernetes 中部署简单演示应用程序所需的所有组件。

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: sample-app
  name: sample-app
  namespace: sample-app
spec:
  replicas: 1
  selector:
    matchLabels:
      app: sample-app
  template:
    metadata:
      labels:
        app: sample-app
    spec:
      containers:
      - image: <image>
        name: sample-app-container
        ports:
        - containerPort: 8080
---
apiVersion: v1
kind: Service
metadata:
  name: sample-app-svc
spec:
  selector:
     app: sample-app
  ports:
    - protocol: TCP
      port: 8080
      targetPort: 8080
---
apiVersion: autoscaling/v1
kind: HorizontalPodAutoscaler
metadata:
  name: hpa-sample-app
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: sample-app
  minReplicas: 1
  maxReplicas: 5
  targetCPUUtilizationPercentage: 50
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ingress-sample-app
spec:
  rules:
  - host: sampleapp.foo.org
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: sample-app-svc
            port:
              number: 80
  ingressClassName: nginx
```

As you can see, all the components need to be declared. As you add more configurations you may need to split this into multiple files, and as you add more services you need to manage and create multiple files for them as well.
正如您所看到的，所有组件都需要声明。 当您添加更多配置时，您可能需要将其拆分为多个文件，并且当您添加更多服务时，您还需要为其管理和创建多个文件。

In this second example, we are using Knative to achieve the same result as above.
在第二个示例中，我们使用 Knative 来实现与上面相同的结果。

```yaml
apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: sample-knative-svc
spec:
  template:
    metadata:
      annotations:
        autoscaling.knative.dev/min-scale: "1"
        autoscaling.knative.dev/max-scale: "5"
        autoscaling.knative.dev/initial-scale: "1"
        autoscaling.knative.dev/class: "hpa.autoscaling.knative.dev"
        autoscaling.knative.dev/metric: "cpu"
        autoscaling.knative.dev/target: "50"
    spec:
      containers:
        - image: <image>
          ports:
          - containerPort: 8080
```

As you can see, in only a few lines, all the resources can be created. This is only possible because Knative creates the CRDs that are used to deploy and manage these underlying resources.
正如您所看到的，只需几行，就可以创建所有资源。 这是可能的，因为 Knative 创建了用于部署和管理这些底层资源的 CRD。

### Metrics

Knative supports different popular tools for collecting metrics:
Knative 支持不同的流行工具来收集指标：

- [Prometheus](https://prometheus.io/)

- [OpenTelemetry Collector](https://opentelemetry.io/docs/collector/)

[Grafana](https://grafana.com/oss/) dashboards are available for metrics collected directly with Prometheus.

You can also set up the OpenTelemetry Collector to receive metrics from Knative components and distribute them to other metrics providers that support OpenTelemetry.
您还可以设置 OpenTelemetry Collector 以从 Knative 组件接收指标并将其分发给支持 OpenTelemetry 的其他指标提供程序。

You can’t use OpenTelemetry Collector and Prometheus at the same time. The default metrics backend is Prometheus. See “[Understanding the Collector](https://knative.dev/docs/serving/observability/metrics/collecting-metrics/#understanding-the-collector)” at knative.dev for more info.
您不能同时使用 OpenTelemetry Collector 和 Prometheus。 默认的指标后端是 Prometheus。 有关详细信息，请参阅 knative.dev 上的“了解收集器”。

Knative comes with [pre-configured monitoring components](https://knative.dev/docs/serving/observability/metrics/serving-metrics/#go-runtime-memstats).
Knative 附带预配置的监控组件。

In an environment with Prometheus and Grafana, the [metrics can be exported to Prometheus and presented in a Grafana Dashboard](https://grafana.com/grafana/dashboards/14589-knative-serving-control-plane-efficiency/).
在具有 Prometheus 和 Grafana 的环境中，可以将指标导出到 Prometheus 并显示在 Grafana 仪表板中。

### Conclusion

If you want to use serverless applications but don’t know how to properly manage them without adding more complexity in your setup, Knative could be your answer. It implements great solutions that will help you to implement and manage these applications and improve your deployments without much effort.
如果您想使用无服务器应用程序，但不知道如何在不增加设置复杂性的情况下正确管理它们，Knative 可能是您的答案。 它实施了出色的解决方案，可帮助您实施和管理这些应用程序，并毫不费力地改进您的部署。
